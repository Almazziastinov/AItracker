# Технический отчет о проделанной работе (AI-модуль)

Этот документ описывает реализованный функционал и архитектурные решения, принятые в ходе разработки AI-модуля.

## Общая архитектура

Модуль построен на **FastAPI** (для создания API) и **LangGraph** (для оркестрации LLM-агента). 

Основной флоу обработки запроса:
1.  HTTP-запрос поступает на эндпоинт FastAPI.
2.  Запрос передается в граф LangGraph, который управляет LLM-агентом.
3.  LLM-агент анализирует текст и решает, какие "инструменты" (tools) нужно вызвать.
4.  Инструменты выполняют необходимые действия (сохранение данных, планирование).
5.  Агент генерирует финальный текстовый ответ для пользователя.

---

## Описание компонентов

### 1. Модуль CRUD-операций (`app/crud/actions.py`)

**Назначение:**
Этот модуль имитирует слой доступа к данным (Data Access Layer). На данный момент все данные хранятся в оперативной памяти (в словаре `mock_db`), но функции спроектированы так, чтобы в будущем их можно было легко заменить на реальные запросы к базе данных (например, через SQLAlchemy).

**Реализованные функции:**
- `async def save_event(...)`: Принимает данные события, создает словарь и добавляет его в список `mock_db["events"]`.
- `async def save_task(...)`: Аналогично сохраняет задачу в `mock_db["tasks"]`.
- `async def save_health_metric(...)`: Аналогично сохраняет метрику в `mock_db["health_metrics"]`.
- `async def get_events(user_id)`: **Новая ключевая функция.** Принимает `user_id` и возвращает список всех событий этого пользователя. Используется AI-планировщиком для анализа уже занятых слотов в календаре.

---

### 2. AI-Планировщик (`app/services/ai_planner.py`)

**Назначение:**
Содержит логику автоматического планирования задач в календаре. Это новый, полностью реализованный сервис.

**Ключевая функция:**
- `async def plan_task(task, user_id)`:
  1.  Получает на вход задачу (словарь) и `user_id`.
  2.  Проверяет, есть ли у задачи длительность (`duration_hours`). Если нет, планирование прерывается.
  3.  Вызывает `actions.get_events(user_id)`, чтобы получить текущее расписание пользователя.
  4.  **Алгоритм поиска слота:** Начиная с текущего момента, ищет первый свободный временной слот, достаточный по длительности для задачи. Поиск ведется только в "рабочие часы" (по умолчанию с 9:00 до 21:00) и учитывает уже существующие события.
  5.  При нахождении слота вызывает `actions.save_event`, чтобы создать в календаре новое событие с названием вида "Задача: [название задачи]".

---

### 3. LLM-Агент и Инструменты (`app/services/llm_processor.py`)

**Назначение:**
Ядро модуля. Обрабатывает текст пользователя и решает, какие действия выполнить.

**Обновленная логика:**
- Инструменты `create_event`, `log_health_metric` были **переписаны**. Вместо простого вывода в консоль они теперь вызывают соответствующие `save_*` функции из `actions.py`, выполняя реальное сохранение данных (в `mock_db`).
- Инструмент `create_task` был **значительно доработан**:
    1. Сначала он, как и другие, вызывает `actions.save_task` для сохранения самой задачи.
    2. Затем он проверяет, была ли в запросе указана длительность (`duration_hours`).
    3. Если длительность есть, он **вызывает `ai_planner.plan_task`**, передавая туда созданную задачу, и таким образом запускает процесс автоматического планирования.
    4. Формирует разный текстовый ответ в зависимости от того, удалось ли планировщику найти слот.

---

### 4. Слой API (`app/main.py` и `app/routers/planning.py`)

**Назначение:**
Обеспечивает внешний доступ к функционалу модуля через HTTP.

**Ключевой эндпоинт:**
- `POST /api/v1/process`: Принимает JSON с `user_id` и `text`. Внутри вызывает `run_agent_async` (основную функцию LLM-агента) и возвращает его финальный текстовый ответ. Реализована базовая обработка ошибок и возврат статуса 500 в случае сбоя.

---

### Выявленные ограничения и точки роста

Важное наблюдение из тестов: агент выполняет извлеченные из текста действия (например, создание события и создание задачи) в произвольном порядке. Это может приводить к тому, что задача планируется **до** того, как в календарь добавлено событие из того же запроса. Это известная точка для будущего улучшения (например, через более сложную логику графа или двухэтапный вызов LLM).
